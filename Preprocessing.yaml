name: Preprocess For Vanilla GAN
description: Preprocesses dataset specifically for Vanilla GAN training with UI component optimizations.
inputs:
  - name: train_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String
    description: "Data configuration from LoadDataset"
  - name: model_config
    type: String
    description: "Vanilla GAN model configuration"
outputs:
  - name: processed_data
    type: Dataset
  - name: gan_config
    type: String
    description: "Vanilla GAN configuration for training"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        # Install required dependencies first
        pip install torch torchvision pillow numpy scikit-learn --quiet
        echo "Dependencies installed successfully"
        
        # Then run the Python script
        python -c "
        import sys, os, pickle, json, base64, io, math
        import numpy as np
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset
        from PIL import Image
        from sklearn.preprocessing import LabelEncoder
        
        print('Starting Vanilla GAN Preprocessing for UI Components')
        
        # Parse arguments
        train_data_path = sys.argv[1]
        dataset_info_path = sys.argv[2]
        data_config_str = sys.argv[3]
        model_config_str = sys.argv[4]
        processed_data_path = sys.argv[5]
        gan_config_path = sys.argv[6]
        
        # Load data
        with open(train_data_path, 'rb') as f:
            train_data = pickle.load(f)
        
        with open(dataset_info_path, 'rb') as f:
            dataset_info = pickle.load(f)
        
        # Parse configs
        try:
            data_config = json.loads(data_config_str) if data_config_str else {}
        except:
            data_config = {}
        
        try:
            model_config = json.loads(model_config_str) if model_config_str else {}
        except:
            model_config = {}
        
        print('Processing for VANILLA GAN')
        print('Loaded ' + str(len(train_data)) + ' samples')
        
        # Get parameters from configs - optimized for Vanilla GAN
        image_size = model_config.get('image_size', data_config.get('image_size', 64))
        channels = model_config.get('channels', data_config.get('channels', 3))
        target_size = model_config.get('target_size', image_size)
        background_color = model_config.get('background_color', 'white')
        
        print('Parameters:')
        print('  Model Type: VANILLA GAN')
        print('  Channels: ' + str(channels))
        print('  Target Size: ' + str(target_size))
        print('  Background: ' + background_color)
        
        # Create label encoder for UI component classes
        all_labels = [item['label'] for item in train_data]
        label_encoder = LabelEncoder()
        label_encoder.fit(all_labels)
        unique_classes = label_encoder.classes_.tolist()
        
        print('Classes found: ' + str(unique_classes))
        
        # Define dataset class specifically for Vanilla GAN
        class VanillaGANDataset(Dataset):
            def __init__(self, data_list, transform=None, label_encoder=None, target_size=64, channels=3, bg_color='white'):
                self.data_list = data_list
                self.transform = transform
                self.label_encoder = label_encoder
                self.target_size = target_size
                self.channels = channels
                self.bg_color = bg_color
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                try:
                    img_data = base64.b64decode(item['image_data'])
                    img = Image.open(io.BytesIO(img_data))
                    
                    # Handle RGBA -> RGB conversion for UI components
                    if img.mode == 'RGBA':
                        bg_color = (255, 255, 255) if self.bg_color == 'white' else (0, 0, 0)
                        background = Image.new('RGB', img.size, bg_color)
                        background.paste(img, mask=img.split()[-1])
                        img = background
                    elif self.channels == 1 and img.mode != 'L':
                        img = img.convert('L')
                    elif self.channels == 3 and img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    # IMPORTANT: Flatten for Vanilla GAN (fully connected layers)
                    img = img.view(-1)
                    
                    return img
                except Exception as e:
                    print('Error processing image ' + str(idx) + ': ' + str(e))
                    return torch.zeros(self.target_size * self.target_size * self.channels)
        
        # Create transform optimized for Vanilla GAN
        if channels == 1:
            transform = transforms.Compose([
                transforms.Resize(target_size, interpolation=transforms.InterpolationMode.LANCZOS),
                transforms.ToTensor(),
                transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] for tanh activation
            ])
        else:
            transform = transforms.Compose([
                transforms.Resize(target_size, interpolation=transforms.InterpolationMode.LANCZOS),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1] for tanh activation
            ])
        
        # Create dataset
        dataset = VanillaGANDataset(train_data, transform, label_encoder, target_size, channels, background_color)
        
        # Calculate input dimension for Vanilla GAN (crucial for fully connected layers)
        input_dim = target_size * target_size * channels
        print('Vanilla GAN input dimension: ' + str(input_dim))
        
        # Create data wrapper
        data_wrapper = {
            'dataset': dataset,
            'model_type': 'vanilla_gan',
            'input_dim': input_dim,
            'image_size': target_size,
            'channels': channels,
            'num_samples': len(dataset),
            'num_classes': len(unique_classes),
            'classes': unique_classes,
            'label_encoder': label_encoder,
            'is_flattened': True,
            'original_size': (1056, 91),
            'background_handled': True
        }
        
        # Save processed data
        os.makedirs(os.path.dirname(processed_data_path) or '.', exist_ok=True)
        with open(processed_data_path, 'wb') as f:
            pickle.dump(data_wrapper, f)
        
        # Create Vanilla GAN configuration
        gan_config = {
            'model_type': 'vanilla_gan',
            'input_dim': input_dim,
            'image_size': target_size,
            'channels': channels,
            'num_classes': len(unique_classes),
            'class_names': unique_classes,
            'latent_dim': model_config.get('latent_dim', 100),
            'generator_layers': model_config.get('generator_layers', [256, 512, 1024]),
            'discriminator_layers': model_config.get('discriminator_layers', [1024, 512, 256]),
            'generator_activation': model_config.get('generator_activation', 'relu'),
            'discriminator_activation': model_config.get('discriminator_activation', 'leaky_relu'),
            'output_activation': 'tanh',
            'generator_dropout': model_config.get('generator_dropout', 0.0),
            'discriminator_dropout': model_config.get('discriminator_dropout', 0.3),
            'batch_size': model_config.get('batch_size', 32),
            'learning_rate': model_config.get('learning_rate', 0.0002),
            'beta1': model_config.get('beta1', 0.5),
            'beta2': model_config.get('beta2', 0.999),
            'epochs': model_config.get('epochs', 100),
            'training_algorithm': model_config.get('training_algorithm', 'backprop'),
            'ff_blocks': model_config.get('ff_blocks', 3),
            'ff_epochs_per_block': model_config.get('ff_epochs_per_block', 50),
            'cafo_blocks': model_config.get('cafo_blocks', 3),
            'epochs_per_block': model_config.get('epochs_per_block', 30),
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'log_interval': model_config.get('log_interval', 10),
            'sample_interval': model_config.get('sample_interval', 100),
            'dataset_type': 'ui_components'
        }
        
        # Save GAN config
        os.makedirs(os.path.dirname(gan_config_path) or '.', exist_ok=True)
        with open(gan_config_path, 'w') as f:
            json.dump(gan_config, f, indent=2)
        
        print('Vanilla GAN Preprocessing Complete!')
        print('  Model type: VANILLA GAN')
        print('  Samples processed: ' + str(len(dataset)))
        print('  Input dimension: ' + str(input_dim))
        print('  Image size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        print('  Classes: ' + str(len(unique_classes)) + ' (' + str(unique_classes) + ')')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputPath: train_data}
      - {inputPath: dataset_info}
      - {inputPath: data_config}
      - {inputValue: model_config}
      - {outputPath: processed_data}
      - {outputPath: gan_config}
