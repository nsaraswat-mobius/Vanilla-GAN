name: Trigger Pipeline v26 - Vanilla GAN
description: Triggers Vanilla GAN training pipeline with flattened data format
inputs:
  - name: train_loader_url
    type: String
    description: "URL to Vanilla GAN train loader (flattened data)"
  - name: test_loader_url
    type: String
    description: "URL to Vanilla GAN test loader (flattened data)"
  - name: processed_data_url
    type: String
    description: "URL to full processed Vanilla GAN dataset"
  - name: gan_config_base64_url
    type: String
    description: "URL to base64 encoded GAN config"
  - name: upload_summary_url
    type: String
    description: "URL to upload summary"
  - name: access_token
    type: String
  - name: domain
    type: String
  - name: pipeline_id
    type: String
  - name: experiment_id
    type: String
  - name: master_config
    type: String
  - name: splitting_strategy
    type: String
  - name: num_tasks
    type: Integer
  - name: load_from_cdn
    type: String
  - name: load_from_schema
    type: String
  - name: train_schema
    type: String
  - name: execution_id
    type: String
  - name: cdn_url
    type: String
  - name: get_cdn
    type: String
  - name: userName
    type: String
  - name: password
    type: String
  - name: requestType
    type: String
  - name: productId
    type: String
  - name: iam_domain
    type: String
  - name: dqn_experiment_id
    type: String
  - name: pipeline_domain
    type: String
  - name: dqn_pipeline_id
    type: String
  - name: rlaf_schema
    type: String
  - name: model_id
    type: String
  - name: model_name
    type: String
    description: "Name of the model to be used (Vanilla GAN)"
  - name: project_id
    type: String
    description: "Project ID for schema upload"
  - name: model_schema
    type: String
    description: "Schema ID for model metrics upload"
  - name: eval_schema
    type: String
    description: "Schema ID for evaluation metrics upload"
  - name: architecture_type
    type: String
    description: "Architecture type for the model (vanilla_gan)"
  - name: model_type
    type: String
    description: "Type of model (vanilla_gan)"
  - name: input_dim
    type: String
    description: "Input dimension for Vanilla GAN (flattened)"
  - name: image_size
    type: String
    description: "Original image size before flattening"
  - name: channels
    type: String
    description: "Number of channels"
  - name: is_flattened
    type: String
    description: "Whether data is flattened (always true for Vanilla GAN)"
    
outputs:
  - name: trigger_response
    type: String
  - name: run_id
    type: String
  - name: trigger_status
    type: String

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.8
    command:
      - sh
      - -ec
      - |
        apt-get update > /dev/null && apt-get install -y curl > /dev/null
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, subprocess, json, os, urllib.parse, time, sys, re
        
        parser = argparse.ArgumentParser()
        
        # Vanilla GAN CDN URLs
        parser.add_argument('--train_loader_url', type=str, required=True)
        parser.add_argument('--test_loader_url', type=str, required=True)
        parser.add_argument('--processed_data_url', type=str, required=True)
        parser.add_argument('--gan_config_base64_url', type=str, required=True)
        parser.add_argument('--upload_summary_url', type=str, required=True)
        
        # Authentication
        parser.add_argument('--access_token', type=str, required=True)
        
        # Pipeline configuration
        parser.add_argument('--domain', type=str, required=True)
        parser.add_argument('--pipeline_id', type=str, required=True)
        parser.add_argument('--experiment_id', type=str, required=True)
        
        # Pipeline parameters
        parser.add_argument('--master_config', type=str, required=True)
        parser.add_argument('--splitting_strategy', type=str, required=True)
        parser.add_argument('--num_tasks', type=int, required=True)
        parser.add_argument('--load_from_cdn', type=str, required=True)
        parser.add_argument('--load_from_schema', type=str, required=True)
        parser.add_argument('--cdn_url', type=str, required=True)
        parser.add_argument('--get_cdn', type=str, required=True)
        parser.add_argument('--train_schema', type=str, required=True)
        parser.add_argument('--execution_id', type=str, required=True)
        
        # IAM authentication
        parser.add_argument('--userName', type=str, required=True)
        parser.add_argument('--password', type=str, required=True)
        parser.add_argument('--requestType', type=str, required=True)
        parser.add_argument('--productId', type=str, required=True)
        parser.add_argument('--iam_domain', type=str, required=True)
        
        # DQN/RLAF parameters
        parser.add_argument('--dqn_experiment_id', type=str, required=True)
        parser.add_argument('--pipeline_domain', type=str, required=True)
        parser.add_argument('--dqn_pipeline_id', type=str, required=True)
        parser.add_argument('--rlaf_schema', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        
        # Vanilla GAN parameters
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--model_schema', type=str, required=True)
        parser.add_argument('--eval_schema', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, required=True)
        parser.add_argument('--model_type', type=str, required=True)
        
        # Vanilla GAN specific parameters
        parser.add_argument('--input_dim', type=str, required=True)
        parser.add_argument('--image_size', type=str, required=True)
        parser.add_argument('--channels', type=str, required=True)
        parser.add_argument('--is_flattened', type=str, required=True)
        
        # Outputs
        parser.add_argument('--trigger_response', type=str, required=True)
        parser.add_argument('--run_id', type=str, required=True)
        parser.add_argument('--trigger_status', type=str, required=True)
        
        args = parser.parse_args()
        
        def fix_cdn_url(url):
            print(f"\\n=== Processing URL ===")
            print(f"Input URL: {url}")
            
            # Step 1: First, decode any existing URL encoding
            try:
                url = urllib.parse.unquote(url)
            except:
                pass
            
            print(f"After unquote: {url}")
            
            # Step 2: Handle special patterns for Vanilla GAN
            # Vanilla GAN URLs often contain 'vanilla_gan_' prefix
            if "vanilla_gan_" in url:
                print(f"Found vanilla_gan_ pattern in URL")
            
            # Step 3: Check for single dollar patterns
            single_dollar_patterns = re.findall(r'([a-zA-Z0-9]+)_\$([a-zA-Z0-9]+)', url)
            if single_dollar_patterns:
                print(f"Found single dollar patterns: {single_dollar_patterns}")
                for before, after in single_dollar_patterns:
                    pattern = f"{before}_${after}"
                    replacement = f"{before}_$${after}"
                    url = url.replace(pattern, replacement)
            
            # Step 4: Remove any spaces
            url = url.replace(" ", "")
            
            print(f"After cleanup: {url}")
            
            # Step 5: Properly URL encode for JSON transmission
            if "://" in url:
                parts = list(urllib.parse.urlsplit(url))
                # Encode the path
                parts[2] = urllib.parse.quote(parts[2], safe="/")
                # Encode query
                if parts[3]:
                    parts[3] = urllib.parse.quote(parts[3], safe="=&")
                # Encode fragment
                if parts[4]:
                    parts[4] = urllib.parse.quote(parts[4], safe="")
                encoded_url = urllib.parse.urlunsplit(parts)
            else:
                encoded_url = urllib.parse.quote(url, safe="/:?=&%")
            
            # Encode special characters
            encoded_url = encoded_url.replace("(", "%28")
            encoded_url = encoded_url.replace(")", "%29")
            
            print(f"Final encoded URL: {encoded_url}")
            print(f"URL length: {len(encoded_url)} chars")
            
            return encoded_url
        
        print("=" * 100)
        print("TRIGGER PIPELINE v26 - VANILLA GAN TRAINING WITH FLATTENED DATA")
        print("=" * 100)
        print("SPECIALIZED FOR VANILLA GAN (FULLY CONNECTED ARCHITECTURE)")
        print("=" * 100)
        
        # ============================================================================
        # Create ALL output directories FIRST
        # ============================================================================
        print("\\nCreating output directories...")
        output_paths = [
            args.trigger_response,
            args.run_id,
            args.trigger_status
        ]
        
        for path in output_paths:
            if path:
                dir_path = os.path.dirname(path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    print(f"  Created: {dir_path}")
        
        # Read access token
        with open(args.access_token, 'r') as f:
            access_token = f.read().strip()
        print(f"Access token length: {len(access_token)} chars")
        
        # Fix all CDN URLs
        print("\\nFixing CDN URLs for Vanilla GAN...")
        urls_to_fix = {
            'train_loader_url': args.train_loader_url,
            'test_loader_url': args.test_loader_url,
            'processed_data_url': args.processed_data_url,
            'gan_config_base64_url': args.gan_config_base64_url,
            'upload_summary_url': args.upload_summary_url
        }
        
        fixed_urls = {}
        for key, url in urls_to_fix.items():
            print(f"\\n=== Processing {key} ===")
            fixed_url = fix_cdn_url(url)
            fixed_urls[key] = fixed_url
            print(f" {key} processed (length: {len(fixed_url) if fixed_url else 0} chars)")
        
        # Build trigger URL
        trigger_url = f"{args.domain}/bob-service-test/v1.0/pipeline/trigger/ml?pipelineId={args.pipeline_id}"
        print(f"\\n=== TRIGGER URL ===")
        print(f"Trigger URL: {trigger_url}")
        
        # Build payload for Vanilla GAN
        payload = {
            "pipelineType": "ML",
            "containerResources": {},
            "experimentId": args.experiment_id,
            "enableCaching": True,
            "parameters": {
                # Master config
                "master_config": args.master_config,
                
                # Vanilla GAN specific URLs
                "train_loader_url": fixed_urls['train_loader_url'],
                "test_loader_url": fixed_urls['test_loader_url'],
                "processed_data_url": fixed_urls['processed_data_url'],
                "gan_config_base64_url": fixed_urls['gan_config_base64_url'],
                "upload_summary_url": fixed_urls['upload_summary_url'],
                
                # Model loading parameters
                "load_from_cdn": args.load_from_cdn,
                "load_from_schema": args.load_from_schema,
                "cdn_url": args.cdn_url,
                "get_cdn": args.get_cdn,
                "train_schema": args.train_schema,
                "execution_id": args.execution_id,
                
                # Continual learning parameters
                "splitting_strategy": args.splitting_strategy,
                "num_tasks": str(args.num_tasks),
                
                # IAM authentication parameters
                "userName": args.userName,
                "password": args.password,
                "productId": args.productId,
                "requestType": args.requestType,
                "domain": args.iam_domain,
                
                # DQN/RLAF parameters
                "dqn_experiment_id": args.dqn_experiment_id,
                "pipeline_domain": args.pipeline_domain,
                "dqn_pipeline_id": args.dqn_pipeline_id,
                "rlaf_schema": args.rlaf_schema,
                "model_id": args.model_id,
                
                # Model parameters
                "model_name": args.model_name,
                "project_id": args.project_id,
                "model_schema": args.model_schema,
                "eval_schema": args.eval_schema,
                "architecture_type": args.architecture_type,
                "model_type": args.model_type,
                
                # VANILLA GAN SPECIFIC PARAMETERS
                "input_dim": args.input_dim,
                "image_size": args.image_size,
                "channels": args.channels,
                "is_flattened": args.is_flattened,
                "gan_type": "vanilla_gan",
                "data_format": "flattened",
                "architecture": "fully_connected"
            },
            "version": 1
        }
        
        print("\\n=== PAYLOAD FOR VANILLA GAN PIPELINE ===")
        print("=" * 80)
        print("\\nFULL PAYLOAD JSON:")
        print("=" * 80)
        print(json.dumps(payload, indent=2))
        print("=" * 80)
        
        print(f"\\n=== PAYLOAD DETAILS ===")
        print(f"Pipeline ID (to trigger): {args.pipeline_id}")
        print(f"Experiment ID: {args.experiment_id}")
        print(f"Model Type: {args.model_type}")
        print(f"Architecture Type: {args.architecture_type}")
        print(f"Input Dimension (flattened): {args.input_dim}")
        print(f"Image Size: {args.image_size}")
        print(f"Channels: {args.channels}")
        print(f"Is Flattened: {args.is_flattened}")
        print(f"Number of URLs: {len(fixed_urls)}")
        
        # Print the full curl command
        print("\\n=== FULL CURL COMMAND ===")
        print("=" * 80)
        print()
        print("curl -X POST \\\\")
        print(f"  '{trigger_url}' \\\\")
        print("  -H 'accept: application/json' \\\\")
        print(f"  -H 'Authorization: Bearer {access_token}' \\\\")
        print("  -H 'Content-Type: application/json' \\\\")
        print(f"  -d '{json.dumps(payload)}'")
        print("=" * 80)
        print()
        
        # Save payload to file for manual use
        with open('/tmp/vanilla_gan_pipeline_payload.json', 'w') as f:
            json.dump(payload, f, indent=2)
        print(f"\\nPayload saved to /tmp/vanilla_gan_pipeline_payload.json for manual use")
        
        # Manual trigger instructions
        print("\\n=== MANUAL TRIGGER INSTRUCTIONS ===")
        print("=" * 80)
        print("1. Copy the curl command above")
        print("2. Or use the saved payload file:")
        print(f"   curl -X POST '{trigger_url}' \\\\")
        print("     -H 'accept: application/json' \\\\")
        print(f"     -H 'Authorization: Bearer YOUR_TOKEN_HERE' \\\\")
        print("     -H 'Content-Type: application/json' \\\\")
        print("     -d @/tmp/vanilla_gan_pipeline_payload.json")
        print("=" * 80)
        print()
        
        # Trigger pipeline with retries
        print(f"\\nTriggering Vanilla GAN pipeline...")
        
        curl_command = [
            "curl",
            "--location", trigger_url,
            "--header", "accept: application/json",
            "--header", f"Authorization: Bearer {access_token}",
            "--header", "Content-Type: application/json",
            "--data", json.dumps(payload),
            "--fail",
            "--show-error",
            "--connect-timeout", "30",
            "--max-time", "120"
        ]
        
        retries = 5
        retry_delay = 60
        
        for i in range(retries):
            try:
                print(f"\\n=== Attempt {i+1}/{retries} ===")
                process = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    check=True
                )
                
                print("Trigger successful!")
                print("\\nRaw response:")
                print(process.stdout)
                
                # Try to parse and pretty print the response
                try:
                    response_json = json.loads(process.stdout)
                    print("\\nParsed response:")
                    print(json.dumps(response_json, indent=2))
                    
                    run_id = response_json.get('run_id', response_json.get('id', 'unknown'))
                    print(f"\\n=== RUN ID EXTRACTED ===")
                    print(f"Run ID: {run_id}")
                    print(f"Response keys: {list(response_json.keys())}")
                    
                except json.JSONDecodeError as e:
                    print(f"Could not parse response as JSON: {e}")
                    print(f"Response text: {process.stdout}")
                    run_id = "unknown"
                
                # Save outputs
                with open(args.trigger_response, 'w') as f:
                    json.dump(response_json if 'response_json' in locals() else {"raw_response": process.stdout}, f, indent=2)
                print(f"\\n Saved trigger response to: {args.trigger_response}")
                
                with open(args.run_id, 'w') as f:
                    f.write(str(run_id))
                print(f" Saved run_id to: {args.run_id}")
                
                # Create status summary
                status_summary = {
                    'status': 'success',
                    'run_id': run_id,
                    'pipeline_id': args.pipeline_id,
                    'experiment_id': args.experiment_id,
                    'model_type': 'vanilla_gan',
                    'input_dim': args.input_dim,
                    'urls_provided': list(fixed_urls.keys()),
                    'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ')
                }
                
                with open(args.trigger_status, 'w') as f:
                    json.dump(status_summary, f, indent=2)
                print(f" Saved trigger status to: {args.trigger_status}")
                
                print(f"\\n Vanilla GAN pipeline trigger completed successfully!")
                break
                
            except subprocess.CalledProcessError as e:
                print(f"Attempt {i+1} failed with return code {e.returncode}.")
                print(f"Stderr: {e.stderr}")
                print(f"Stdout: {e.stdout}")
                
                if i < retries - 1:
                    if e.returncode == 22:  # HTTP error
                        print(f"Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        print("Non-retriable error encountered.")
                        break
                else:
                    print("Max retries reached. Saving error info...")
                    
                    error_info = {
                        'status': 'failed',
                        'error': e.stderr[:500] if e.stderr else str(e),
                        'exit_code': e.returncode,
                        'stdout': e.stdout[:500] if e.stdout else None,
                        'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                        'attempts': retries
                    }
                    
                    with open(args.trigger_response, 'w') as f:
                        json.dump(error_info, f, indent=2)
                    
                    with open(args.run_id, 'w') as f:
                        f.write("failed")
                    
                    with open(args.trigger_status, 'w') as f:
                        json.dump({'status': 'failed', 'model_type': 'vanilla_gan'}, f, indent=2)
                    
                    print(" Vanilla GAN pipeline trigger failed after all retries")
                    sys.exit(1)
                    
            except Exception as e:
                print(f" Unexpected error: {str(e)}")
                import traceback
                traceback.print_exc()
                
                error_info = {
                    'status': 'error',
                    'error': str(e),
                    'traceback': traceback.format_exc(),
                    'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'model_type': 'vanilla_gan'
                }
                
                with open(args.trigger_response, 'w') as f:
                    json.dump(error_info, f, indent=2)
                
                with open(args.run_id, 'w') as f:
                    f.write("error")
                
                with open(args.trigger_status, 'w') as f:
                    json.dump({'status': 'error', 'model_type': 'vanilla_gan'}, f, indent=2)
                
                sys.exit(1)
        
    args:
      # Vanilla GAN CDN URL inputs
      - --train_loader_url
      - {inputValue: train_loader_url}
      - --test_loader_url
      - {inputValue: test_loader_url}
      - --processed_data_url
      - {inputValue: processed_data_url}
      - --gan_config_base64_url
      - {inputValue: gan_config_base64_url}
      - --upload_summary_url
      - {inputValue: upload_summary_url}
      - --access_token
      - {inputPath: access_token}
      - --domain
      - {inputValue: domain}
      - --pipeline_id
      - {inputValue: pipeline_id}
      - --experiment_id
      - {inputValue: experiment_id}
      - --master_config
      - {inputValue: master_config}
      - --splitting_strategy
      - {inputValue: splitting_strategy}
      - --num_tasks
      - {inputValue: num_tasks}
      - --load_from_cdn
      - {inputValue: load_from_cdn}
      - --load_from_schema
      - {inputValue: load_from_schema}
      - --cdn_url
      - {inputValue: cdn_url}
      - --get_cdn
      - {inputValue: get_cdn}
      - --train_schema
      - {inputValue: train_schema}
      - --execution_id
      - {inputValue: execution_id}
      - --userName
      - {inputValue: userName}
      - --password
      - {inputValue: password}
      - --requestType
      - {inputValue: requestType}
      - --productId
      - {inputValue: productId}
      - --iam_domain
      - {inputValue: iam_domain}
      - --dqn_experiment_id
      - {inputValue: dqn_experiment_id}
      - --pipeline_domain
      - {inputValue: pipeline_domain}
      - --dqn_pipeline_id
      - {inputValue: dqn_pipeline_id}
      - --rlaf_schema
      - {inputValue: rlaf_schema}
      - --model_id
      - {inputValue: model_id}
      - --model_name
      - {inputValue: model_name}
      - --project_id
      - {inputValue: project_id}
      - --model_schema
      - {inputValue: model_schema}
      - --eval_schema
      - {inputValue: eval_schema}
      - --architecture_type
      - {inputValue: architecture_type}
      - --model_type
      - {inputValue: model_type}
      - --input_dim
      - {inputValue: input_dim}
      - --image_size
      - {inputValue: image_size}
      - --channels
      - {inputValue: channels}
      - --is_flattened
      - {inputValue: is_flattened}
      - --trigger_response
      - {outputPath: trigger_response}
      - --run_id
      - {outputPath: run_id}
      - --trigger_status
      - {outputPath: trigger_status}
